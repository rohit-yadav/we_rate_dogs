{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# We Rate Dogs\n",
    "\n",
    "WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "I will do a wrangling, analyzing and visualization of the tweet data of the WeRateDogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud,STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter api\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "# Function to get twitter connection\n",
    "def twitter_connection(consumer_key, consumer_secret, access_token, access_secret):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = twitter_connection(consumer_key, consumer_secret, access_token, access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading data from the url\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "\n",
    "# Request the url\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the downloaded data\n",
    "folder_name = 'data'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "with open('data/image_predictions.tsv', 'wb') as file:\n",
    "    file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a data frame\n",
    "archive_df = pd.read_csv(\"data/twitter-archive-enhanced.csv\")\n",
    "predictions_df = pd.read_csv(\"data/image_predictions.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting tweet ids\n",
    "archive_tweet_id = list(archive_df.tweet_id)\n",
    "prediction_tweet_id = list(predictions_df.tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archive_tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2075"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = archive_tweet_id + prediction_tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4431"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping unique tweet ids\n",
    "tweet_ids = list(set(tweet_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting tweet details from the API and storing it in a .txt file\n",
    "# Collecting id which are still there\n",
    "working_ids = []\n",
    "\n",
    "# Tweet id of tweet which are deleted\n",
    "removed_ids = []\n",
    "\n",
    "def get_tweet_details():\n",
    "    if os.path.isfile(\"data/tweet_json.txt\"):\n",
    "        print(\"File exists, no need to extract again\")\n",
    "        value = 0\n",
    "    else:\n",
    "        # Count the progress\n",
    "        count = 0\n",
    "\n",
    "        # Opening a file to write on\n",
    "        with open('data/tweet_json.txt', 'w') as file:\n",
    "            start = time.time()\n",
    "            for tweet_id in tweet_ids:\n",
    "                count = count + 1\n",
    "                # Writing the data to a file - line by line\n",
    "                try:\n",
    "                    status = api.get_status(tweet_id, tweet_mode = 'extended')\n",
    "                    file.write(json.dumps(status._json))\n",
    "                    file.write('\\n')\n",
    "                    working_ids.append(tweet_id)\n",
    "                    print(\"{}) Successful id: {}\".format(count, tweet_id))\n",
    "                # Handeling exception\n",
    "                except:\n",
    "                    removed_ids.append(tweet_id)\n",
    "                    print(\"{}) Failed id: {}\".format(count, tweet_id))\n",
    "            end = time.time()\n",
    "            print(\"Time taken: {}\".format(end - start))\n",
    "        value = 1\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists, no need to extract again\n"
     ]
    }
   ],
   "source": [
    "value = get_tweet_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is alread present so this is not needed\n"
     ]
    }
   ],
   "source": [
    "if value == 1:\n",
    "    print(len(working_ids))\n",
    "    print(len(removed_ids))\n",
    "else:\n",
    "    print(\"File is alread present so this is not needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To hold the tweets details\n",
    "all_tweets = []\n",
    "\n",
    "# Read the file to add the details to a list\n",
    "with open(\"data/tweet_json.txt\") as f:\n",
    "    for line in f:\n",
    "        # Converting the string into a dictionary\n",
    "        data = json.loads(line) \n",
    "        all_tweets.append(data)\n",
    "\n",
    "# Creating a data frame with all the tweet details\n",
    "all_tweet_df = pd.DataFrame(all_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we have three data frames**\n",
    "- all_tweet_df - Extracted from the API\n",
    "- archive_df - Got from Udacity\n",
    "- predictions_df- Downloaded from the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
